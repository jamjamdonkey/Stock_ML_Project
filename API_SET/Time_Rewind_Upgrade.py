import requests
import pandas as pd
import re
from bs4 import BeautifulSoup
from datetime import datetime
import os

# ë„¤ì´ë²„ ì¦ê¶Œ API í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤
class NaverStockAPI:
    def __init__(self):
        self.base_url = "https://m.stock.naver.com/api/stock"

    def clean_market_cap(self, market_cap_str):
        if not market_cap_str:
            return None
        ì¡°_match = re.search(r"([\d,\.]+)ì¡°", market_cap_str)
        ì–µ_match = re.search(r"([\d,\.]+)ì–µ", market_cap_str)
        ì¡° = float(ì¡°_match.group(1).replace(",", "")) if ì¡°_match else 0
        ì–µ = float(ì–µ_match.group(1).replace(",", "")) if ì–µ_match else 0
        return int(ì¡° * 10**12 + ì–µ * 10**8)

    def clean_number_with_units(self, num_str):
        if not num_str:
            return None
        cleaned = re.sub(r"[^\d\.]", "", num_str)
        try:
            return float(cleaned.replace(",", ""))
        except:
            return None

    def get_today_stock_info(self, stock_code):
        url = f"{self.base_url}/{stock_code}/integration"
        try:
            response = requests.get(url)
            response.raise_for_status()
            data = response.json()

            ì¢…ëª©ëª… = data.get("stockName", "")
            total_infos = data.get("totalInfos", [])
            deal_trends = data.get("dealTrendInfos", [])
            def find_value(code):
                for info in total_infos:
                    if info.get("code") == code:
                        return info.get("value", "")
                return ""

            trend = deal_trends[0] if deal_trends else {}

            raw_market_cap = find_value("marketValue")
            raw_per = find_value("per")
            raw_eps = find_value("eps")

            return {
                "ì¢…ëª©ì½”ë“œ": stock_code,
                "ì¢…ëª©ëª…": ì¢…ëª©ëª…,
                "ë‚ ì§œ": trend.get("bizdate", ""),
                "ì‹œì‘ê°€": find_value("openPrice"),
                "ì „ì¼ê°€": find_value("lastClosePrice"),
                "ì •ì _ê±°ë˜ëŸ‰": find_value("accumulatedTradingVolume"),
                "ì‹œê°€ì´ì•¡": self.clean_market_cap(raw_market_cap),
                "PER": self.clean_number_with_units(raw_per),
                "EPS": self.clean_number_with_units(raw_eps),
                "52ì£¼ìµœê³ ": find_value("highPriceOf52Weeks"),
                "52ì£¼ìµœì €": find_value("lowPriceOf52Weeks"),
                "ì¢…ê°€": trend.get("closePrice", ""),
                "ì „ì¼ëŒ€ë¹„": trend.get("compareToPreviousClosePrice", ""),
                "ì™¸êµ­ì¸ìˆœë§¤ìˆ˜": trend.get("foreignerPureBuyQuant", ""),
                "ê¸°ê´€ìˆœë§¤ìˆ˜": trend.get("organPureBuyQuant", ""),
                "ê°œì¸ìˆœë§¤ìˆ˜": trend.get("individualPureBuyQuant", ""),
                "ë™ì _ê±°ë˜ëŸ‰": trend.get("accumulatedTradingVolume", ""),
                "ì‹œê°€ì´ì•¡_ì›": self.clean_market_cap(raw_market_cap),
                "PER_ìˆ«ì": self.clean_number_with_units(raw_per),
                "EPS_ìˆ«ì": self.clean_number_with_units(raw_eps)
            }

        except requests.exceptions.RequestException as e:
            print(f"[ì—ëŸ¬] API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def get_today_multiple_stocks(self, stock_codes):
        results = []
        for code in stock_codes:
            info = self.get_today_stock_info(code)
            if info:
                results.append(info)
        return pd.DataFrame(results)


# ì‹œê°€ì´ì•¡ ìƒìœ„ 50ê°œ ì¢…ëª© ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
def get_top_kospi_50():
    stock_list = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    url = 'https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page=1'
    res = requests.get(url, headers=headers)
    soup = BeautifulSoup(res.text, 'html.parser')
    table = soup.select('table.type_2 tr')[2:]
    for row in table:
        link = row.select_one('a.tltle')
        if link:
            name = link.text.strip()
            href = link['href']
            code = href.split('=')[-1]
            stock_list.append({'ì¢…ëª©ëª…': name, 'ì¢…ëª©ì½”ë“œ': code})
    return pd.DataFrame(stock_list).drop_duplicates().reset_index(drop=True)


# ğŸ¯ ì‹¤í–‰: ì›í•˜ëŠ” ë‚ ì§œ ë²”ìœ„ ìë™ ë°˜ë³µ + íœ´ì¥ì¼/ì¤‘ë³µ ì €ì¥ ë°©ì§€ ê¸°ëŠ¥ í¬í•¨
if __name__ == "__main__":
    from datetime import datetime, timedelta
    import os
    import pandas as pd

    # ğŸ”½ ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ ë²”ìœ„ ì„¤ì •
    start_date = datetime.strptime("20250102", "%Y%m%d")
    end_date   = datetime.strptime("20250110", "%Y%m%d")
    cur_date   = start_date

    while cur_date <= end_date:
        target_date = cur_date.strftime("%Y%m%d")
        prev_date   = (cur_date - timedelta(days=1)).strftime("%Y%m%d")
        print(f"\nğŸ“… ì‹¤í–‰ ì¤‘: {target_date}")

        try:
            # 1. ì¢…ëª© ì½”ë“œ ìˆ˜ì§‘
            top50_df = get_top_kospi_50()
            stock_codes = top50_df["ì¢…ëª©ì½”ë“œ"].tolist()

            # 2. ì£¼ê°€ ì •ë³´ ìˆ˜ì§‘
            api = NaverStockAPI()
            df = api.get_today_multiple_stocks(stock_codes)

            if df.empty:
                print(f"âŒ {target_date}: ë°ì´í„° ì—†ìŒ (ì£¼ë§ or íœ´ì¥ì¼ ê°€ëŠ¥)")
                cur_date += timedelta(days=1)
                continue

            # 3. ì„ íƒ í”¼ì²˜ ì¶”ì¶œ
            selected_columns = [
                "ì¢…ëª©ì½”ë“œ", "ì¢…ëª©ëª…", "ë‚ ì§œ",
                "ì¢…ê°€", "52ì£¼ìµœê³ ", "52ì£¼ìµœì €",
                "ì •ì _ê±°ë˜ëŸ‰", "ë™ì _ê±°ë˜ëŸ‰",
                "ì‹œê°€ì´ì•¡_ì›", "PER_ìˆ«ì", "EPS_ìˆ«ì",
                "ì „ì¼ëŒ€ë¹„", "ê°œì¸ìˆœë§¤ìˆ˜", "ê¸°ê´€ìˆœë§¤ìˆ˜", "ì™¸êµ­ì¸ìˆœë§¤ìˆ˜"
            ]
            eda_df = df[selected_columns]

            # 4. ì „ë‚  ì‚¼ì„±ì „ì ì§€í‘œì™€ ë¹„êµ
            eda_path = f"EDA_CSV/EDA_{target_date}.csv"
            prev_path = f"EDA_CSV/EDA_{prev_date}.csv"
            skip_save = False

            if os.path.exists(prev_path):
                try:
                    prev_df = pd.read_csv(prev_path)

                    # ì‚¼ì„±ì „ì ë°ì´í„° ìœ ë¬´ í™•ì¸
                    if "005930" in eda_df["ì¢…ëª©ì½”ë“œ"].values and "005930" in prev_df["ì¢…ëª©ì½”ë“œ"].values:
                        today_row = eda_df[eda_df["ì¢…ëª©ì½”ë“œ"] == "005930"].iloc[0]
                        prev_row  = prev_df[prev_df["ì¢…ëª©ì½”ë“œ"] == "005930"].iloc[0]
                        key_cols = ["ì¢…ê°€", "PER_ìˆ«ì", "EPS_ìˆ«ì", "ë™ì _ê±°ë˜ëŸ‰"]

                        if all(today_row[col] == prev_row[col] for col in key_cols):
                            print(f"â© {target_date}: ì£¼ìš” ì§€í‘œ ë™ì¼ â†’ ì €ì¥ ìƒëµ")
                            skip_save = True
                    else:
                        print(f"âš ï¸ ì‚¼ì„±ì „ì ë°ì´í„° ì—†ìŒ â†’ ì €ì¥ ì§„í–‰")
                except Exception as e:
                    print(f"âš ï¸ ì‚¼ì„±ì „ì ë¹„êµ ì¤‘ ì˜ˆì™¸ ë°œìƒ â†’ ì €ì¥ ì§„í–‰ (ì—ëŸ¬: {e})")

            # 5. ì €ì¥ (CSV + EDA)
            if not skip_save:
                os.makedirs("CSV", exist_ok=True)
                csv_file_name = f"{target_date}.csv"
                df.to_csv(os.path.join("CSV", csv_file_name), index=False, encoding="utf-8-sig")
                print(f"âœ” ì €ì¥ ì™„ë£Œ: CSV/{csv_file_name}")

                os.makedirs("EDA_CSV", exist_ok=True)
                eda_df.to_csv(eda_path, index=False, encoding="utf-8-sig")
                print(f"ğŸ“Š [EDA ì €ì¥ ì™„ë£Œ] {eda_path}")

        except Exception as e:
            print(f"â— ì˜¤ë¥˜ ë°œìƒ: {target_date} â†’ {e}")

        # ë‚ ì§œ 1ì¼ ì¦ê°€
        cur_date += timedelta(days=1)
